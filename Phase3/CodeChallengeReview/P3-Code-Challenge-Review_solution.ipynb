{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Code Challenge Review\n",
    "\n",
    "Made using resources from the Seattle team - thanks y'all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "* Gradient Descent\n",
    "* Logistic Regression\n",
    "* Classification Metrics\n",
    "* Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "#from sklearn.tree import export_graphviz\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.call import call_on_students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data from 'auto-mpg.csv'\n",
    "mpg_df = pd.read_csv(\"data/auto-mpg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a simple linear regression line using just the horsepower column\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x='horsepower', y='mpg', data=mpg_df, line_kws={\"color\":\"orange\"})\n",
    "plt.title('Relationship Between Horsepower and MPG')\n",
    "plt.xlim(0, 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows an approximate best fit line for the relationship between `horsepower` and `mpg` in our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Describe the below chart: What is it showing? What does it tell us?\n",
    "\n",
    "![Slope-RSS relationship image](img/slope-rss-relationship.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- Plot shows the error (RSS) on the y-axis and the slope of the model on the x-axis\n",
    "- From this graph you can see that it arrived at about `m = -0.158` for the optimal coefficient value, since it's around that point that the error term (RSS) is smallest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Imagine that you're starting at a slope towards the top upper left corner. Using Zoom's annotate feature, demonstrate how gradient descent would work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) What is a step size when talking about gradient descent? How does learning rate regulate step size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- Step size captures the amount to change the coefficient as it tries to minimize the error term\n",
    "- Learning rate determines how large those steps are to start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Describe a logistic regression model:\n",
    "\n",
    "- What kind of target is a logistic regression model used for?\n",
    "- What are the predictions that a logistic regression model outputs?\n",
    "- How is it different from linear regression?\n",
    "- Is it a parametric or non-parametric model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- Used for classification problems (categorical targets)\n",
    "- Log-odds, which are translated into probabilities\n",
    "- Linear regression predicts a continuous target, and is not bound between 0 and 1\n",
    "- Parametric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Compare a logistic regression model to any of the other model types we've learned:\n",
    "\n",
    "- List one benefit of logistic regression when compared to the other model type\n",
    "- List one reason the other model type might be more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- Benefit: simple to interpret, fits quickly, not prone to overfitting\n",
    "- Another model might be more useful if the target is imbalanced, or if there are interaction terms in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Logistic Regression and Classification Metrics with Code\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the same data, but now with a classification target\n",
    "mpg_class = pd.read_csv('data/auto-mpg-classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this new dataframe out\n",
    "mpg_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Prepare our data for modeling:\n",
    "\n",
    "1. Perform a train/test split\n",
    "2. Scale the inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "# Set test_size=0.33 and random_state=42\n",
    "X = mpg_class.drop(columns='target')\n",
    "y = mpg_class['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Explore the `target` column and our model-less baseline\n",
    "\n",
    "1. What is the breakdown of the `target` column in our training data?\n",
    "2. What would a model-less baseline look like in this context?\n",
    "3. How accurate would that model-less understanding be on our test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: explore the target column breakdown in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to explore\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- Imbalanced target - 74% of training data is in class 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: What would a model-less baseline look like in this context?\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "- Predicting only our majority class, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: How accurate would that baseline be on test data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to find the answer\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- 75% accurate on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) What is one problem you could foresee based on this breakdown, and what is one strategy you could employ to address that problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- Target is imbalanced\n",
    "- Oversampling, synthetic oversampling (SMOTE), set `class_weight`\n",
    "- Note that undersampling doesn't make sense here, since our dataset is so small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Fit a logistic regression model, and plot a confusion matrix of the results on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model\n",
    "# Name the model `logreg` and set random_state = 42\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix on the test data\n",
    "plot_confusion_matrix(logreg, X_test_scaled, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Calculate the accuracy, precision, recall and f1-score for the test set\n",
    "\n",
    "You can use the confusion matrix above, or sklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab predictions if using sklearn functions\n",
    "test_preds = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# By hand: TP + TN / TP + TN + FP + FN\n",
    "accuracy = (23 + 97) / (23 + 97 + 1 + 9)\n",
    "print(accuracy)\n",
    "\n",
    "# Using sklearn\n",
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "# By hand: TP / TP + FP\n",
    "precision = 23 / (23 + 1)\n",
    "print(precision)\n",
    "\n",
    "# Using sklearn\n",
    "precision = precision_score(y_test, test_preds)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "# By hand: TP / TP + FN\n",
    "recall = 23 / (23 + 9)\n",
    "print(recall)\n",
    "\n",
    "# Using sklearn\n",
    "recall = recall_score(y_test, test_preds)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score\n",
    "# By hand\n",
    "f1score = 2 * precision * recall / (precision + recall)\n",
    "print(f1score)\n",
    "\n",
    "# Using sklearn\n",
    "f1score = f1_score(y_test, test_preds)\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Calculate the ROC-AUC on the test set, and plot the ROC curve\n",
    "\n",
    "For this you'll definitely want to use the sklearn functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate roc-auc\n",
    "# Need predicted probabilities\n",
    "test_probas = logreg.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "roc_auc_score(y_test, test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "plot_roc_curve(logreg, X_test_scaled, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12) Evaluate! Based on the metrics of our test data, how is our model doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- Doing well! Very high metrics all around - more FN than FP (better precision than recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from a colleague (h/t Bryan)\n",
    "def plot_tree(dt, used_cols, out_file='mytree.dot'):\n",
    "    export_graphviz(dt, out_file=out_file, \n",
    "                    filled=True, feature_names=used_cols, \n",
    "                    leaves_parallel=True, node_ids=True)\n",
    "    with open(out_file) as f:\n",
    "        dot_graph = f.read()\n",
    "    return graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating two different decision trees with a single split\n",
    "dt_maxdepth1_v1 = DecisionTreeClassifier(max_depth=1, random_state = 42)\n",
    "dt_maxdepth1_v2 = DecisionTreeClassifier(max_depth=1, random_state = 42)\n",
    "\n",
    "# Training the two trees on different columns\n",
    "dt_maxdepth1_v1.fit(X_train[['weight']], y_train)\n",
    "dt_maxdepth1_v2.fit(X_train[['origin']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tree based on 1st column\n",
    "plot_tree(dt_maxdepth1_v1, ['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree based on 2nd column\n",
    "plot_tree(dt_maxdepth1_v2, ['origin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13) Which of these trees does a better job splitting the data? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- The first DT produces more pure splits, thus is doing a better job of separating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14) Fit a decision tree model, and plot a confusion matrix of the results on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a decision tree model\n",
    "# Name the model `dt` and set random_state = 42\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a confusion matrix on the test data\n",
    "plot_confusion_matrix(dt, X_test_scaled, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the ROCs for the models we've done\n",
    "fig, ax = plt.subplots()\n",
    "plot_roc_curve(dt, X_test_scaled, y_test, ax=ax)\n",
    "plot_roc_curve(logreg, X_test_scaled, y_test, ax=ax)\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic Curves\\n(Evaluated on Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15) Which is the better model according to ROC-AUC score? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_on_students(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- Logistic regression has the higher roc-auc score, and has more area under the curve since it's closer to the top left corner of the graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
